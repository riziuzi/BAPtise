{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Wikipedia:Contents/Technology_and_applied_sciences 28 0\n",
      "https://en.wikipedia.org/wiki/Human 95 1\n",
      "https://en.wikipedia.org/wiki/Prehistory 35 1\n",
      "https://en.wikipedia.org/wiki/Fire 34 1\n",
      "https://en.wikipedia.org/wiki/Wheel 43 1\n",
      "https://en.wikipedia.org/wiki/Printing_press 57 1\n",
      "https://en.wikipedia.org/wiki/Internet 101 1\n",
      "https://en.wikipedia.org/wiki/Communication 75 1\n",
      "https://en.wikipedia.org/wiki/Weapon 34 1\n",
      "https://en.wikipedia.org/wiki/Club_(weapon) 16 1\n",
      "https://en.wikipedia.org/wiki/Nuclear_bomb 94 1\n",
      "https://en.wikipedia.org/wiki/Applied_science 15 1\n",
      "https://en.wikipedia.org/wiki/Natural_science 58 1\n",
      "https://en.wikipedia.org/wiki/Engineering 91 1\n",
      "https://en.wikipedia.org/wiki/Research_and_development 21 1\n",
      "https://en.wikipedia.org/wiki/Technology 60 1\n",
      "https://en.wikipedia.org/wiki/List_of_applied_sciences 2 1\n",
      "https://en.wikipedia.org/wiki/Accelerating_change 25 1\n",
      "https://en.wikipedia.org/wiki/Appropriate_technology 28 1\n",
      "https://en.wikipedia.org/wiki/Diffusion_of_innovations 52 1\n",
      "https://en.wikipedia.org/wiki/Doomsday_device 7 1\n",
      "https://en.wikipedia.org/wiki/High_technology 6 1\n",
      "https://en.wikipedia.org/wiki/History_of_science_and_technology 19 1\n",
      "https://en.wikipedia.org/wiki/History_of_technology 103 1\n",
      "https://en.wikipedia.org/wiki/Industry 1 1\n",
      "https://en.wikipedia.org/wiki/Innovation 72 1\n",
      "https://en.wikipedia.org/wiki/Knowledge_economy 21 1\n",
      "https://en.wikipedia.org/wiki/Persuasion_technology 33 1\n",
      "https://en.wikipedia.org/wiki/Pollution 67 1\n",
      "https://en.wikipedia.org/wiki/Posthumanism 23 1\n",
      "https://en.wikipedia.org/wiki/Precautionary_principle 67 1\n",
      "https://en.wikipedia.org/wiki/Strategy_of_technology 11 1\n",
      "https://en.wikipedia.org/wiki/Superpower 27 1\n",
      "https://en.wikipedia.org/wiki/Technocapitalism 6 1\n",
      "https://en.wikipedia.org/wiki/Technocriticism 5 1\n",
      "https://en.wikipedia.org/wiki/Techno-progressivism 8 1\n",
      "https://en.wikipedia.org/wiki/Technological_convergence 48 1\n",
      "https://en.wikipedia.org/wiki/Technological_evolution 13 1\n",
      "https://en.wikipedia.org/wiki/Technological_determinism 34 1\n",
      "https://en.wikipedia.org/wiki/Diffusion_(business) 4 1\n",
      "https://en.wikipedia.org/wiki/Technological_singularity 103 1\n",
      "https://en.wikipedia.org/wiki/Technology_acceptance_model 18 1\n",
      "https://en.wikipedia.org/wiki/Technology_assessment 11 1\n",
      "https://en.wikipedia.org/wiki/Technology_lifecycle 35 1\n",
      "https://en.wikipedia.org/wiki/Technology_transfer 30 1\n",
      "https://en.wikipedia.org/wiki/Technology_tree 18 1\n",
      "https://en.wikipedia.org/wiki/Technorealism 4 1\n",
      "https://en.wikipedia.org/wiki/Timeline_of_invention 9 1\n",
      "https://en.wikipedia.org/wiki/Transhumanism 97 1\n",
      "https://en.wikipedia.org/wiki/List_of_basic_technology_topics 7 1\n",
      "https://en.wikipedia.org/wiki/Applied_sciences 15 1\n",
      "https://en.wikipedia.org/wiki/Aerospace 25 1\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import urllib.parse\n",
    "import validators\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "directory = \"D:\\deep_data\\wiki_technicalTermLabeledData\"\n",
    "\n",
    "if not os.path.exists(directory):         # Ensures to make directory\n",
    "    os.makedirs(directory)\n",
    "\n",
    "\n",
    "\n",
    "q = deque()\n",
    "set_depth = 4\n",
    "base_url=\"https://en.wikipedia.org\"\n",
    "parent_url = \"https://en.wikipedia.org/wiki/Wikipedia:Contents/Technology_and_applied_sciences\"\n",
    "q.append((parent_url,0))\n",
    "checked=[]\n",
    "repeated=[]\n",
    "excpt = []\n",
    "time_max = 0\n",
    "\n",
    "count1 = count2 = count3 = count4 = 0\n",
    "\n",
    "while(len(q)):\n",
    "    front = q.popleft()                     # Basic BFS settings\n",
    "    url = front[0]\n",
    "    time = front[1]\n",
    "    time_max = max(time_max, time)\n",
    "    \n",
    "    if(time_max>set_depth):\n",
    "      q.appendleft((front,time))\n",
    "      break\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    paragraphs = soup.find_all(\"p\")\n",
    "    print(url,len(paragraphs),time)\n",
    "    count1+=1\n",
    "    for j in range(len(paragraphs)):              # Inserting new links (according to given depth) to queue (BFS fashion)\n",
    "      count2+=1\n",
    "      if len(paragraphs[j].find_all(\"a\"))!=0:\n",
    "        list2=[]\n",
    "        for i in paragraphs[j].find_all(\"a\"):\n",
    "          try:\n",
    "            count3+=1\n",
    "            if i.get(\"href\") not in checked and validators.url(i.get(\"href\")):\n",
    "              checked.append(i.get(\"href\"))\n",
    "              count4+=1\n",
    "              q.append((i.get(\"href\"),time+1))\n",
    "            elif base_url+i.get(\"href\") not in checked and validators.url(base_url+i.get(\"href\")):\n",
    "              checked.append(base_url+i.get(\"href\"))\n",
    "              count4+=1\n",
    "              q.append((base_url+i.get(\"href\"),time+1))\n",
    "            else:\n",
    "              repeated.append(url)\n",
    "              count4+=0\n",
    "          except Exception:\n",
    "            excpt.append([url])\n",
    "            print(\"cought exception for \",url,i)\n",
    "\n",
    "    texts = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    for paragraph in paragraphs:          # Extrcating labeled and unlabeled data\n",
    "      text = paragraph.get_text()\n",
    "      texts.append(text)\n",
    "      links = paragraph.find_all(\"a\")\n",
    "      label = [link.get_text() for link in links]\n",
    "      labels.append(label)\n",
    "      count+=1\n",
    "\n",
    "    dict1 = {}                            # Saving\n",
    "    for i in range(count):\n",
    "      dict1[texts[i]] = labels[i]\n",
    "    with open(os.path.join(directory,str(time)+urllib.parse.quote(url, safe=\"\")+\".json\"),\"w\") as file:\n",
    "      json.dump(dict1, file, indent=\"\")\n",
    "      \n",
    "\n",
    "deque_list = list(q)      # Save the list to a JSON file\n",
    "with open(os.path.join(directory,\"deque_data.json\"), \"w\") as file:\n",
    "    json.dump(deque_list, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15891 11960\n",
      "173 level 1 urls + 1(for level0) + 1(for level2)\n",
      "6349 sum(len(paragraphs of level0))\n",
      "27851 sum(all links at level 1)\n",
      "15891 sum of unchecked + checked links\n"
     ]
    }
   ],
   "source": [
    "print(len(checked),len(repeated))\n",
    "print(count1,\"level 1 urls + 1(for level0) + 1(for level2)\")\n",
    "print(count2,\"sum(len(paragraphs of level0))\")\n",
    "print(count3,\"sum(all links at level 1)\")\n",
    "print(count4,\"sum of unchecked + checked links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
