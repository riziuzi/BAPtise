{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting filter words sytem using NLTK libary by defining Loader class architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "\n",
    "class Loader:\n",
    "    def __init__(self,path ='./0.parquet'):\n",
    "        nltk.download(\"words\")\n",
    "        self.english_words_set = set(words.words())\n",
    "        self.df = pd.DataFrame()\n",
    "        self.list0 = []\n",
    "        self.list1 = []\n",
    "        self.path = path\n",
    "        \n",
    "        \n",
    "    def filter_lists(self):\n",
    "        if(len(self.list0)==0):\n",
    "            self.parquet_traverse()\n",
    "        for i in range(len(self.list0)):\n",
    "            paragraph_list0 = self.list0[i][0]\n",
    "            label_list0 = self.list0[i][1]\n",
    "            paragraph_list1 = []\n",
    "            label_list1 = []\n",
    "            for i in range(len(paragraph_list0)):\n",
    "                word_tokens = nltk.word_tokenize(paragraph_list0[i])\n",
    "                dummy_list = [word for word in word_tokens if word.lower() in self.english_words_set]\n",
    "                paragraph_list1.append(dummy_list)\n",
    "                word_tokens = nltk.word_tokenize(\" \".join(label_list0[i]))\n",
    "                dummy_list = [word for word in word_tokens if word.lower() in self.english_words_set]\n",
    "                label_list1.append(dummy_list)\n",
    "            self.list1.append([paragraph_list1, label_list1])\n",
    "    \n",
    "    def load_parquet(self ):\n",
    "        try:\n",
    "            table = pq.read_table(self.path)\n",
    "            self.df = table.to_pandas()\n",
    "        except Exception as x:\n",
    "            print(x)\n",
    "            return\n",
    "        \n",
    "    def parquet_traverse(self):\n",
    "        if(len(self.df)==0):\n",
    "            self.load_parquet()\n",
    "        for i in range(len(self.df)):\n",
    "            dict1 = self.df.iloc[i,i]\n",
    "            paragraph_list1 = [i for i in dict1.keys()]\n",
    "            label_list1 = [dict1[i] for i in dict1.keys()]\n",
    "            label_list1 = [list(i) for i in label_list1]\n",
    "            self.list0.append([paragraph_list1, label_list1])\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\rishi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "data_loader = Loader(path ='./0.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.filter_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = data_loader.list1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining architecture for preparing the data for Model (model oriented architecture)\n",
    "#### Included: HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list1[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareData:\n",
    "    def __init__(self):\n",
    "        self.paragraphs = []\n",
    "        self.highlighted_words = []\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        self.input_ids_tensor = torch.tensor([])\n",
    "        self.attention_masks_tensor = torch.tensor([])\n",
    "        self.labels_tensor = torch.tensor([])\n",
    "    \n",
    "    def __init__(self, paragraphs, highlighted_words):\n",
    "        self.paragraphs = paragraphs\n",
    "        self.highlighted_words = highlighted_words\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        self.input_ids_tensor = torch.tensor([])\n",
    "        self.attention_masks_tensor = torch.tensor([])\n",
    "        self.labels_tensor = torch.tensor([])\n",
    "\n",
    "    def prepare_tensors(self):\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        labels = []\n",
    "        for paragraph_list, highlighted_list in zip(self.paragraphs, self.highlighted_words):\n",
    "            paragraph = \" \".join(paragraph_list)\n",
    "            tokenized_inputs = self.tokenizer.encode_plus(\n",
    "                paragraph,\n",
    "                add_special_tokens=True,\n",
    "                max_length=128,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            input_ids.append(tokenized_inputs['input_ids'].squeeze())\n",
    "            attention_masks.append(tokenized_inputs['attention_mask'].squeeze())\n",
    "\n",
    "            label = np.zeros(tokenized_inputs['input_ids'].shape[1])\n",
    "            for word in highlighted_list:\n",
    "                if word in self.tokenizer.tokenize(paragraph):\n",
    "                    token_indices = self.tokenizer.encode(word, add_special_tokens=False)\n",
    "                    label[np.where(np.isin(tokenized_inputs['input_ids'].squeeze(), token_indices))] = 1\n",
    "            labels.append(torch.tensor(label))\n",
    "\n",
    "            self.input_ids_tensor = torch.stack(input_ids)\n",
    "            self.attention_masks_tensor = torch.stack(attention_masks)\n",
    "            self.labels_tensor = torch.stack(labels)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.paragraphs = []\n",
    "        self.highlighted_words = []\n",
    "        self.input_ids_tensor = torch.tensor([])\n",
    "        self.attention_masks_tensor = torch.tensor([])\n",
    "        self.labels_tensor = torch.tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28,\n",
       " tensor([[1, 1, 0,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 0,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_ids_tensor,\n",
    "# attention_masks_tensor,  \n",
    "len(labels_tensor),attention_masks_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101,  102,    0,  ...,    0,    0,    0],\n",
       "        [ 101, 5237, 3330,  ...,    0,    0,    0],\n",
       "        [ 101, 4162, 2671,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 5193, 3665,  ...,    0,    0,    0],\n",
       "        [ 101,  102,    0,  ...,    0,    0,    0],\n",
       "        [ 101, 8417, 2974,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " ['Agriculture',\n",
       "  'engineering',\n",
       "  'Air',\n",
       "  'pollution',\n",
       "  'dispersion',\n",
       "  'terminology',\n",
       "  'Engineering',\n",
       "  'Fuel',\n",
       "  'cell',\n",
       "  'equipment',\n",
       "  'Heating',\n",
       "  'ventilation',\n",
       "  'Metalworking',\n",
       "  'terminology',\n",
       "  'Mill',\n",
       "  'machinery',\n",
       "  'Telephony',\n",
       "  'Textile',\n",
       "  'Woodworking',\n",
       "  'Joinery'],\n",
       " ['Applied',\n",
       "  'science',\n",
       "  'is',\n",
       "  'the',\n",
       "  'application',\n",
       "  'of',\n",
       "  'knowledge',\n",
       "  'from',\n",
       "  'one',\n",
       "  'or',\n",
       "  'more',\n",
       "  'natural',\n",
       "  'scientific',\n",
       "  'to',\n",
       "  'practical',\n",
       "  'For',\n",
       "  'example',\n",
       "  'of',\n",
       "  'engineering',\n",
       "  'are',\n",
       "  'applied',\n",
       "  'Applied',\n",
       "  'science',\n",
       "  'is',\n",
       "  'important',\n",
       "  'for',\n",
       "  'technology',\n",
       "  'development',\n",
       "  'Its',\n",
       "  'use',\n",
       "  'in',\n",
       "  'industrial',\n",
       "  'is',\n",
       "  'usually',\n",
       "  'to',\n",
       "  'as',\n",
       "  'research',\n",
       "  'and',\n",
       "  'development',\n",
       "  'R',\n",
       "  'D'],\n",
       " ['Architecture', 'and', 'Construction'],\n",
       " ['Artificial',\n",
       "  'intelligence',\n",
       "  'Computer',\n",
       "  'Computer',\n",
       "  'science',\n",
       "  'and',\n",
       "  'IT',\n",
       "  'and',\n",
       "  'IT',\n",
       "  'and',\n",
       "  'data',\n",
       "  'Alternative',\n",
       "  'for',\n",
       "  'free',\n",
       "  'Unified',\n",
       "  'Modeling',\n",
       "  'Language',\n",
       "  'Machine',\n",
       "  'vision',\n",
       "  'slang'],\n",
       " ['Automotive',\n",
       "  'design',\n",
       "  'Aviation',\n",
       "  'and',\n",
       "  'aeronautics',\n",
       "  'Nautical',\n",
       "  'Rail',\n",
       "  'Passenger',\n",
       "  'rail',\n",
       "  'railway',\n",
       "  'railway',\n",
       "  'railway',\n",
       "  'Road',\n",
       "  'trucking',\n",
       "  'industry'],\n",
       " ['and', 'information', 'technology'],\n",
       " ['Open',\n",
       "  'source',\n",
       "  'GNU',\n",
       "  'Operating',\n",
       "  'running',\n",
       "  'Graphics',\n",
       "  'file',\n",
       "  'Test',\n",
       "  'Screen'],\n",
       " ['Electronics', 'Home'],\n",
       " ['Technology'],\n",
       " ['Engineering'],\n",
       " ['List', 'of', 'in', 'science', 'in', 'science', 'of', 'historic'],\n",
       " ['Fire'],\n",
       " ['Indices'],\n",
       " ['Military'],\n",
       " ['More', 'about', 'Technology', 'and', 'Applied'],\n",
       " ['people', 'and', 'times'],\n",
       " ['Space',\n",
       "  'exploration',\n",
       "  'Unmanned',\n",
       "  'space',\n",
       "  'Human',\n",
       "  'by',\n",
       "  'program',\n",
       "  'Space',\n",
       "  'of',\n",
       "  'by',\n",
       "  'nationality',\n",
       "  'List',\n",
       "  'of'],\n",
       " ['Technological',\n",
       "  'and',\n",
       "  'change',\n",
       "  'Appropriate',\n",
       "  'technology',\n",
       "  'Diffusion',\n",
       "  'of',\n",
       "  'in',\n",
       "  'science',\n",
       "  'Doomsday',\n",
       "  'device',\n",
       "  'High',\n",
       "  'technology',\n",
       "  'History',\n",
       "  'of',\n",
       "  'science',\n",
       "  'and',\n",
       "  'technology',\n",
       "  'History',\n",
       "  'of',\n",
       "  'technology',\n",
       "  'Industry',\n",
       "  'Innovation',\n",
       "  'Knowledge',\n",
       "  'economy',\n",
       "  'Persuasion',\n",
       "  'technology',\n",
       "  'Pollution',\n",
       "  'Precautionary',\n",
       "  'principle',\n",
       "  'Research',\n",
       "  'and',\n",
       "  'development',\n",
       "  'Strategy',\n",
       "  'of',\n",
       "  'technology',\n",
       "  'Technological',\n",
       "  'convergence',\n",
       "  'Technological',\n",
       "  'evolution',\n",
       "  'Technological',\n",
       "  'determinism',\n",
       "  'Technological',\n",
       "  'diffusion',\n",
       "  'Technological',\n",
       "  'singularity',\n",
       "  'Technology',\n",
       "  'acceptance',\n",
       "  'model',\n",
       "  'Technology',\n",
       "  'assessment',\n",
       "  'Technology',\n",
       "  'Technology',\n",
       "  'transfer',\n",
       "  'Technology',\n",
       "  'tree',\n",
       "  'of',\n",
       "  'invention'],\n",
       " ['and', 'applied'],\n",
       " ['and',\n",
       "  'applied',\n",
       "  'Agriculture',\n",
       "  'Agricultural',\n",
       "  'science',\n",
       "  'Agronomy',\n",
       "  'Architecture',\n",
       "  'Automobile',\n",
       "  'Big',\n",
       "  'science',\n",
       "  'Cartography',\n",
       "  'Communication',\n",
       "  'Construction',\n",
       "  'Design',\n",
       "  'Electronics',\n",
       "  'Energy',\n",
       "  'development',\n",
       "  'Energy',\n",
       "  'storage',\n",
       "  'Engineering',\n",
       "  'Chemical',\n",
       "  'engineering',\n",
       "  'Civil',\n",
       "  'engineering',\n",
       "  'Electrical',\n",
       "  'engineering',\n",
       "  'Mechanical',\n",
       "  'engineering',\n",
       "  'Food',\n",
       "  'science',\n",
       "  'Forestry',\n",
       "  'Free',\n",
       "  'Health',\n",
       "  'Health',\n",
       "  'Industry',\n",
       "  'Information',\n",
       "  'science',\n",
       "  'Library',\n",
       "  'and',\n",
       "  'information',\n",
       "  'science',\n",
       "  'Management',\n",
       "  'Mass',\n",
       "  'communication',\n",
       "  'Mass',\n",
       "  'production',\n",
       "  'Medicine',\n",
       "  'Unsolved',\n",
       "  'in',\n",
       "  'Military',\n",
       "  'science',\n",
       "  'Military',\n",
       "  'technology',\n",
       "  'and',\n",
       "  'equipment',\n",
       "  'Mining',\n",
       "  'Nuclear',\n",
       "  'technology',\n",
       "  'and',\n",
       "  'Space',\n",
       "  'exploration',\n",
       "  'Technology',\n",
       "  'forecasting'],\n",
       " ['Technology',\n",
       "  'making',\n",
       "  'usage',\n",
       "  'and',\n",
       "  'knowledge',\n",
       "  'of',\n",
       "  'or',\n",
       "  'of',\n",
       "  'organization',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'a',\n",
       "  'problem',\n",
       "  'or',\n",
       "  'perform',\n",
       "  'a',\n",
       "  'specific',\n",
       "  'function',\n",
       "  'It',\n",
       "  'can',\n",
       "  'also',\n",
       "  'refer',\n",
       "  'to',\n",
       "  'the',\n",
       "  'collection',\n",
       "  'of',\n",
       "  'such',\n",
       "  'machinery',\n",
       "  'and'],\n",
       " ['The',\n",
       "  'human',\n",
       "  'race',\n",
       "  'use',\n",
       "  'of',\n",
       "  'technology',\n",
       "  'with',\n",
       "  'the',\n",
       "  'conversion',\n",
       "  'of',\n",
       "  'plentiful',\n",
       "  'natural',\n",
       "  'into',\n",
       "  'simple',\n",
       "  'The',\n",
       "  'prehistorical',\n",
       "  'discovery',\n",
       "  'of',\n",
       "  'the',\n",
       "  'ability',\n",
       "  'to',\n",
       "  'control',\n",
       "  'fire',\n",
       "  'the',\n",
       "  'available',\n",
       "  'of',\n",
       "  'food',\n",
       "  'and',\n",
       "  'the',\n",
       "  'invention',\n",
       "  'of',\n",
       "  'the',\n",
       "  'wheel',\n",
       "  'in',\n",
       "  'in',\n",
       "  'and',\n",
       "  'their',\n",
       "  'environment',\n",
       "  'Recent',\n",
       "  'technological',\n",
       "  'the',\n",
       "  'printing',\n",
       "  'press',\n",
       "  'and',\n",
       "  'the',\n",
       "  'have',\n",
       "  'physical',\n",
       "  'to',\n",
       "  'communication',\n",
       "  'and',\n",
       "  'to',\n",
       "  'interact',\n",
       "  'on',\n",
       "  'a',\n",
       "  'global',\n",
       "  'scale',\n",
       "  'However',\n",
       "  'not',\n",
       "  'all',\n",
       "  'technology',\n",
       "  'been',\n",
       "  'used',\n",
       "  'for',\n",
       "  'peaceful',\n",
       "  'the',\n",
       "  'development',\n",
       "  'of',\n",
       "  'of',\n",
       "  'destructive',\n",
       "  'power',\n",
       "  'throughout',\n",
       "  'history',\n",
       "  'from',\n",
       "  'to',\n",
       "  'nuclear'],\n",
       " [],\n",
       " ['Transport'],\n",
       " ['Transportation', 'Transport'],\n",
       " [],\n",
       " ['contents', 'Technology', 'and', 'applied']]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'agriculture'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([5237])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_tensor[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = PrepareData(list1[0][0],list1[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.prepare_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.labels_tensor[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
